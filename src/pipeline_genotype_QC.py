# Hello

##############################################################################
#
#   Imperial College London
#
#   $Id$
#
#   Copyright (C) 2017 Antonio Berlanga-Taylor
#
#   This program is free software; you can redistribute it and/or
#   modify it under the terms of the GNU General Public License
#   as published by the Free Software Foundation; either version 3
#   of the License, or (at your option) any later version.
#
#   This program is distributed in the hope that it will be useful,
#   but WITHOUT ANY WARRANTY; without even the implied warranty of
#   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#   GNU General Public License for more details.
#
#   You should have received a copy of the GNU General Public License
#   along with this program; if not, write to the Free Software
#   Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
###############################################################################

#########################
#Genotype QC pipeline
#Pre-processing of raw genotype data for use as plink input and QC to eliminate markers and individuals.
#Antonio J Berlanga-Taylor
#########################


"""===========================
Pipeline genotype QC
===========================

:Author: Antonio Berlanga-Taylor
:Release: $Id$
:Date: |today|
:Tags: Python

.. Replace the documentation below with your own description of the
   pipeline's purpose

Overview
========

##Quality control of subject and SNP genotyping data
# Note this is now using plink 1.9, which is currently in beta

This pipeline pre-processes genome-wide genotype data from a microarray (Illumina, Affymetrix) and carries out quality control
processing. It outputs varies plots, tables and a final QC'd file for downstream analysis (GWAS, imputation, etc.).

See the files :file:``pipeline.ini` and :file:`conf.py` to configure with different parameters and reporting.

The pipeline is based on the UK Biobank protocol and other methods. See references. 

It requires CGAT tools (pipelines and scripts).

See notes and further information in:
https://github.com/EpiCompBio/genotype_tools/blob/master/todo_genotype_QC.rst

Anderson et al. 2010 protocol: http://www.nature.com/nprot/journal/v5/n9/pdf/nprot.2010.116.pdf
Winkler et al. 2014 protocol (meta-analysis of GWAS): http://www.nature.com/nprot/journal/v9/n5/pdf/nprot.2014.071.pdf
Plink tutorial: http://pngu.mgh.harvard.edu/~purcell/plink/tutorial.shtml

Usage
=====

See :ref:`PipelineSettingUp` and :ref:`PipelineRunning` on general
information how to use CGAT pipelines.
See also Ruffus to understand how pipelines can be re-started from
different points.

The workflow of the pipeline can be as follows:

1. Run the ``full`` target to perform initial QC on the raw data. Then
   build the report (``build_report`` target).
2. Inspect the output (plots, tables, frequency reports, etc. 
   to decide if parameters need to be changed.
3. Edit the configuration file ``pipeline.ini`` or create a new directory
   and re-run from the raw data.
4. Alternatively, run up to intermediate targets, particularly if you have
   a large dataset and want to inspect results and plots before continuing.


Configuration
-------------

The pipeline requires a configured :file:`pipeline.ini` file.
CGATReport report requires a :file:`conf.py` and optionally a
:file:`cgatreport.ini` file (see :ref:`PipelineReporting`).

Default configuration files can be generated by executing:

   python <srcdir>/pipeline_genotype_QC.py config

Input files
-----------

Genotype file as provided by Illumina, Affymetrix or converted to Plink formats.

TO DO: For pre-processing input is an Illumina SNP genotype file

Requirements
------------

The pipeline requires various tools to be installed:

Requirements:

Default CGAT setup: 
* CGATPipelines
* cgat tools

* Plink 1.90
* R
* FlashPCA: ftp://pricelab:pricelab@ftp.broadinstitute.org/EIGENSOFT/EIG6.0.1.tar.gz
* aberrant: http://www.well.ox.ac.uk/~spencer/Aberrant/aberrant-manual.pdf
* Some plotting scripts and others from Anderson et al 2010 protocol

TODO: add versions

Pipeline output
===============

Outputs a genetic marker and individual QC'd file in plink's format plus various descriptive plots and tables 
in a simple report.


Glossary
========

.. glossary::



References
==========

General protocols and references:
http://www.ukbiobank.ac.uk/wp-content/uploads/2014/04/UKBiobank_genotyping_QC_documentation-web.pdf
http://www.nature.com/nprot/journal/v5/n9/pdf/nprot.2010.116.pdf
http://www.nature.com/nprot/journal/v10/n9/pdf/nprot.2015.077.pdf
http://www.nature.com/ng/journal/vaop/ncurrent/pdf/ng.3656.pdf

Also see:
Quality control and conduct of genome-wide association meta-analyses
http://www.nature.com/nprot/journal/v9/n5/full/nprot.2014.071.html

Basic statistical analysis in genetic case-control studies
http://www.nature.com/nprot/journal/v6/n2/abs/nprot.2010.182.html


Other references to check:
==========================

Eagle v2.3 User Manual
https://data.broadinstitute.org/alkesgroup/Eagle/

Reference-based phasing using the Haplotype Reference Consortium panel : Nature Genetics : Nature Research
http://www.nature.com/ng/journal/v48/n11/full/ng.3679.html

Population-specific genotype imputations using minimac or IMPUTE2 - nprot.2015.077.pdf
http://www.nature.com/nprot/journal/v10/n9/pdf/nprot.2015.077.pdf

ExonChipProcessing/BatchAlleleFreqMatrix.R at master Â· slzhao/ExonChipProcessing
https://github.com/slzhao/ExonChipProcessing/blob/master/BatchAlleleFreqMatrix.R

gabraham/flashpca: Fast Principal Component Analysis of Large-Scale Genome-Wide Data
https://github.com/gabraham/flashpca#R

Scaling probabilistic models of genetic variation to millions of humans : Nature Genetics : Nature Research
http://www.nature.com/ng/journal/v48/n12/full/ng.3710.html

Testing for genetic associations in arbitrarily structured populations : Nature Genetics : Nature Research
http://www.nature.com/ng/journal/v47/n5/full/ng.3244.html

LD Score regression distinguishes confounding from polygenicity in genome-wide association studies
http://www.nature.com/ng/journal/v47/n3/full/ng.3211.html
https://github.com/bulik/ldsc

Also check if Variance inflation factor need calculating and adjusting for. See methods in:
Identification of 15 genetic loci associated with risk of major depression in individuals of European descent
http://www.nature.com/ng/journal/v48/n9/full/ng.3623.html
500,000 subjects


Code
====

"""

#####################################################################
#####################################################################
# Several of the following functions are from CGATPipelines
#####################################################################

from ruffus import *

import sys
import os
import sqlite3
import glob
import re
import shutil

import pandas as pd
import numpy as np

import CGAT.Experiment as E
import CGATPipelines.Pipeline as P
import CGAT.Database as DB
import CGAT.IOTools as IOTools


##################################################################################
##################################################################################
# Get parameters, check file inputs, error if none or not the correct file formats
##################################################################################

# load options from the config file:
PARAMS = P.getParameters(
    ["%s/pipeline.ini" % os.path.splitext(__file__)[0],
     "../pipeline.ini",
     "pipeline.ini"])

#TO DO: update this to take .txt files from Illumina, from Affy or 
# directly from plink format
# list of acceptable input formats
INPUT_FORMATS = ["*.bed", "*.txt"]

# Check there is at least one input file (one bed, there should be bim and fam as well though):
# TO DO:
if len(xxx check os.sys for dir for INPUT_FORMATS) == 0:
    raise ValueError('''No input files in the working directory.
		     Binary plink input files are needed (bed, bim and fam, see 
		     https://www.cog-genomics.org/plink2/formats#bed ; If you only have a .bed 
		     generate a .bim and a dummy .fam''')
else:
    # Regular expression to get the prefix for a file:
    REGEX_FILE = r"([^/]+).(bed|txt)"

# Check if there is a bim and fam files as well:
# TO DO: How to handle downstream if there is only a bed file (and no bim and fam)? Error here for now, 
# easier to leave to user.

# TO DO: dummy function that calls the pipeline.ini PARAMS options for [plink]
def plinkXXX(infile, outfiles):
        '''process xxx.
        '''
        plink_options = PARAMS["plink_options"]

########################
########################
# CGATPipeline function:
########################

# -----------------------------------------------
# Utility functions

def connect():
	'''
    utility function to connect to database.

    Use this method to connect to the pipeline database.
    Additional databases can be attached here as well.

    Returns an sqlite3 database handle.
	'''

    dbh = sqlite3.connect(PARAMS["database_name"])
    statement = '''ATTACH DATABASE '%s' as annotations''' % (
        PARAMS["annotations_database"])
    cc = dbh.cursor()
    cc.execute(statement)
    cc.close()

    return dbh


#########################################
#########################################
# Set up some general job mission options
#########################################

# Set-up per job, leave global definitions based on CGAT's priority handling, in beta though but current form works:
#https://github.com/CGATOxford/CGATPipelines/pull/254

#to_cluster = True
#job_threads = 
#job_memory = 



#########################
#########################
# Specific pipeline tasks
#########################

'''
General pipeline steps:
-----

A. Pre-QC steps, GenomeStudio to plink, hg19 liftover, flip strand:

# TO DO: load into pipeline by calling each script or function. Needs a if/else decision (if illumina, convert to xxx, if affy do xxx, else error):

#Data management see:
#Convert files from raw genotypes to Plink's lgen, map and ped formats:
#http://pngu.mgh.harvard.edu/~purcell/plink/data.shtml#ped
#https://www.biostars.org/p/10332/
#http://pngu.mgh.harvard.edu/~purcell/plink/data.shtml#map

From Gao, check if we can run the simple commands I have instead (to reduce external script dependency):

	1. GenomeStudio to plink: by zcall script:
		Script: /groupvol/med-bio/epiUKB/Airwave/coreExome_zcall/zcall_v3.4/convertReportToTPED.py
		Job submission script: /groupvol/med-bio/epiUKB/Airwave/coreExome_genotype/plinkFiles/1_convertReportToTPED.pbs
		Result files: /groupvol/med-bio/epiUKB/Airwave/coreExome_genotype/plinkFiles

	2. Convert from AB allele to illumina TOP/BOT annotation: by plink, using Wrayner's annotation files
		Strand files: /groupvol/med-bio/epiUKB/Airwave/strandFiles
		(from http://www.well.ox.ac.uk/~wrayner/strand/)
		Command: plink --noweb --bfile --update-alleles humancoreexome-12v1-1_a.update_alleles.txt --make-bed --out

	3. Update genome build: hg19/build 37 liftover: by plink, using Wrayner's annotation files, also handles strand
		This includes updating a few attributes (chromosome, position, strand flipping etc)
		Script: http://www.well.ox.ac.uk/~wrayner/strand/update_build.sh
'''

# TO DO: check call to params, active if illumina = true:
@active_if(PARAMS["illumina"])
@transform(("*.txt",
	    suffix(".txt"),
	    "")
def convertIllumina(infile, outfile):
    '''
    Convert Illumina's Beadstudio output (e.g. 'xxx_FinalReport.txt') into 
    Plink's lgen, map, ped and fam formats.
    Check Plink output for results: log file, nof (nofounder) report, nosex (ambiguous sex) report.
    '''

	# Convert from raw to lgen
	# Convert from raw to map
	# Use lgen and map to obtain fam (lgen file has no paternal/maternal IDs, sex or phenotype information 
	# so are set to missing, see below for generating new fam file and alternate phenotype file)
	# Use lgen, fam and map to generate ped

    # the command line statement we want to execute:

    statement = '''
        cat %(infile)s | cut -f1,2,17,18 | sed "1,10d" | sed "s/-/0/g" | awk '{print $2,$2,$1,$3,$4}' > %(outfile)s.lgen;
        checkpoint;
        cat %(infile)s | cut -f1,19,20 | sed "1,10d" | awk '{print $2,$1,"0",$3}' | sort -u > %(outfile)s.map;
        checkpoint;
        perl -ane '{print "$F[0] $F[0] 0 0 0 -9\n"}' %(outfile)s.lgen | sort -u -k1,1 > %(outfile)s.fam;
        checkpoint;
        plink2 --noweb --lfile %(outfile)s --recode --out %(outfile)s.ped;
        checkpoint;
        touch %(outfile)s;
        '''

	# Generate binary files with plink2 (faster reading):
	# To disable the automatic setting of the phenotype to missing if the individual has an ambiguous 
	# sex code, add the --allow-no-sex option.
	# Sanity check with plink2 to see if file is intact and generate some summary stats. 
	# Results should be the same as log file generated from converting to binary file
    statement = '''
        plink2 --noweb --file %(outfile)s --make-bed --out %(outfile)s;
        checkpoint;
        plink2 --noweb --bfile %(outfile)s;
        '''

    # execute command in variable statement.
    # The command will be sent to the cluster.  The statement will be
    # interpolated with any options that are defined in in the
    # configuration files or variable that are declared in the calling
    # function.  For example, %(infile)s will we substituted with the
    # contents of the variable "infile".
    P.run()


# Generate a baseline report of allele frequencies:
#plink --bfile $plink_bfile --freqx --out $plink_bfile

	   
'''
# Dummy function, loads data to a database, this is a CGAT function:
@transform(countWords,
           suffix(".counts"),
           "_counts.load")
def loadWordCounts(infile, outfile):
    " '''load results of word counting into database.''' " 
    P.load(infile, outfile, "--add-index=word")

# TO DO: Also see (from Steve S. pipeline):
@merge(counts,
       "counts.dir/counts.load")
def loadCounts(infiles, outfile):

    P.concatenateAndLoad(infiles, outfile,
                         regex_filename=".*/(.*).counts.gz",
                         has_titles=False,
                         cat="track",
                         header="track,ID,counts",
                         options='-i "ID"',
                         job_memory=PARAMS["xxx"])


# TO DO: Also see (from Steve S. pipeline):

@transform(someResults,
           suffix(".log"),
           ".load")
def loadSuperResult(infile, outfile):
    '''load the xxx results/processed data table from xxx function into the database'''

    my_table = os.path.dirname(infile) + "/my_name.my_table"

    P.load(my_table, outfile, 
	   options='-i "tracking_id"')

'''
           
@follows(xxx)
def preProcessIllumina():
    '''preProcessIllumina target'''
    pass


#########################		   

'''
-----

B. Allele frequency report with proportions:
	TO DO write commands into ruffus pipeline, e.g. (see also sh scripts above):
	plink2 --bifle xxx --freq
	cat plink.frq | tr -s ' ' '\t' | cut -f 4 | grep A | wc -l # First column is a tab, so fourth is A1
'''

# Get frequency stats:
#plink --bfile chr22_Airwave_CPMG_Plasma --freq --out test_chr22.test

@follows(xxx)
def alleleFreq():
    '''alleleFreq target'''
    pass


'''
-----

#. Select homogeneous set of samples to use as set for marker QC (PCA based, with automatic selection using e.g. 'aberrant' R package. This is to avoid artefacts from population structure. Excluded samples are later re-introduced.):
	http://bioinformatics.oxfordjournals.org/content/28/1/134.full.pdf+html
	Use summary statistics, and/or: missingness, ancestry, probe intensity, gender separately:
	TO DO write commands into ruffus pipeline:
		- Merge plates first
		
	TO DO write commands into ruffus pipeline (see scripts above although PCA tool needs changing to FlashPCA probably as older tools won't run on large number of samples):
		- Run PCA against 1000G (or Hapmap) as in UKB appendix 1 (requires using plink MAF >5%, HWE 10^-6, etc for Hapmap or 1000G, then projecting onto these)
		
	TO DO write script to wrap aberrant and make it callable from CLI within pipeline:	
		- aberrant with lambda set to 20 for ancestry PC1 and PC2 as summary stats

'''

# Run loop to convert vcf to binary and subset individuals:
# Bash loop to process with qsub (use #Ruffus!):
#qsub PBS_plink_subset_loop.sh      
           
# Create list of subsetted files:
#ls -1 *.subset.bed > list_subsetted_files.txt

# Merge all resulting plink binaries into one file:
#plink --make-bed --bfile [?] --merge-list list_subsetted_files.txt --out Airwave_imputed_metabolomics_subset

# TO DO: smartpca libopenblas.so.0 missing; GSL library needed; run flashpca otherwise but need to adapt r script for plotting
           
@follows(xxx)
def homogeneousSet():
    '''homogeneousSet target'''
    pass


'''
-----

#. Per batch marker QC (plink commands; drop failing SNPs from all plates):
	- TO DO write script for this, needs loop calling batch 1 vs all other batches, then batch 2 vs all other batches, etc. with parameters (eg p-values and all the criteria below) can be set by user:
		+ Exclude monomorphic SNPs
		+ Genotype call rate (<98%)
		+ Genotype frequency consistency across batches (Fisher's exact test p-value <10^-12)
		+ Allele frequency consistency versus reference panel (eg Hapmap, Fisher's exact test p-value <10^-12)
		+ Hardy Weinberg equilibrium (p-value <10^-12)

'''

'''
1)	Identification of SNPs with excessive missing call rates
#Calculate the missing genotype rate for each marker. Output will be .lmiss (variant-based missing data report) and .imiss (sample-based missing data report):

plink --bfile $plink_bfile --missing --out $plink_bfile

#Plot a histogram of the missing genotype rate (.lmiss data) to identify a threshold for extreme genotype failure rate. Use column 5 of the .lmiss file 
#and the lmiss-hist.Rscript file. A call-rate threshold of 3% is suggested.
# Run R script with file (minus suffix as argument)

#Rscript ${script_basename}lmiss-hist_modified.R $plink_bfile

#2)	Identification of differing genotype call rates between cases and controls
#Test all markers for differences in call rate between cases and controls. Output will be in .missing file:

plink --bfile $plink_bfile --test-missing --allow-no-sex --out $plink_bfile

#Create a file that contains all SNPs with a significantly different (P<0.00001) missing data rate between cases and controls. 
#Output will be in 'fail-diffmiss-qc.txt'.
# I modified the file run-diffmiss-qc.pl to run-diffmiss-qc_p-value_0.01.pl with higher p-value:
 
perl ${script_basename}run-diffmiss-qc_p-value_0.01.pl $plink_bfile

#3)	SNP quality (filtering of monomorphic SNPs, SNPs with missing values or nonsense values; imputation quality; low call rate; 
#violation of Hardy-Weinberg Equilibrium; duplication; and minimum allele frequency). 
# Exclude all non-autosomal and unplaced variants including mitochondrial, X and Y chromosomes (with --autosome or use --chr and specify, eg --chr 1-22):
#Remove poor SNPs and create a clean GWA data file. SNPs failing previous QC steps, those with an MAF<0.10 and an HWE P-value < 0.00001 (in controls) 
#are removed. 

#Filtering criteria of SNPs for BEST-D:
# SNPs with significantly different missing rate between cases and controls (fail-diffmiss file from steps 1 to 3)
# Sample and SNP call rates above 98%
# Minor allele frequency (MAF) of 10% 
# Hardy-Weinberg equilibrium threshold of 1x10-6
# Markers which are unplaced or not in chr 1-22 (all non-autosomal SNPs)

plink --bfile $plink_bfile --maf 0.05 --geno 0.05 --hwe 0.00001 --autosome --exclude fail-diffmiss-qc.txt --make-bed \
	--out ${plink_bfile}_clean_SNPs_autosome

# Generate a report of allele frequencies after removal of low quality markers:
plink --bfile ${plink_bfile}_clean_SNPs_autosome --freqx --out ${plink_bfile}_clean_SNPs_autosome


#Individuals and SNPs failing QC steps will be removed and reported at each step. 
#References: PLINK (Purcell, Neale et al., 2007), related software and protocols (Anderson, Pettersson et al., 2010; Winkler, Day et al., 2014; Sham and #Purcell, 2014).

#TO DO / CHECK if needed:
#High LD regions removal (get file)
#Look for finer population substructure

#########################

'''


@follows(xxx)
def markerQC():
    '''markerQC target'''
    pass


'''
-----

#. Plate/batch PCA (visual outlier detection check)
	TO DO clean up commands from above and plotting script for this (may need substantial re-working with tools that take thousands of samples, check notes/discuss)

'''

@follows(xxx)
def PCA():
    '''PCA target'''
    pass

'''
-----

#. Plate/batch merge
	TO DO write scripts/commands

'''

@follows(xxx)
def mergePlates():
    '''mergePlates target'''
    pass

'''
-----

#. Visual test of genotype calls in cluster plots (bin by MAF, pick random subset)
	TO DO write scripts for this: Gao has plotted these before and I think has scripts. Obviously can't check thousands of SNPs visually svo either use a random pick (e.g. grab 20 or whatever is plottable) or better grab top 10 highest quality SNPs, bottom 10, 10 failed SNPs, 10 at MAF > 10%, 10 at 1-5%, 10 <1%, etc. The aim is to have some visual sanity check of the raw data for some of the markers.

'''



@follows(xxx)
def SNPcluster():
    '''SNPcluster target'''
    pass

'''
-----
#Removal of low-quality individuals from genotype file
#. Pooled sample QC (all samples; based on high quality set of markers from above; plink commands):
	TO DO these are plink commands that can be put directly into the ruffus pipeline with a PARAMS config option so user can set different cut-offs (these PARAMS and config file are standard for CGAT pipelines):
     - Run with autosomal SNPs only
     - Heterozygosity (standard deviation > +/- 3) and genotype failure rates per individual (>5%)
     - Relatedness between individuals (IBD cut-off >0.185)
     - Gender mis-identification check

'''

#########################
bfile=$1
#bfile="P140343-Results_FinalReport"
SNPs_of_interest=$2
#SNPs_of_interest="gwas-association-downloaded_2016-07-28-fibrinogen.tsv"
base_directory_scripts=$3
#base_directory_scripts="/home/aberlang/bin/bin_symlinks/"
#########################
##a.	Gender mis-identification
#See http://www.nature.com/nprot/journal/v5/n9/pdf/nprot.2010.116.pdf (reference as above)

#Calculate the mean homozygosity rate across X-chromosome markers for each individual in the study:
# If running after markers QC (to prioritise keeping individuals over markers for a study with low sample size), run sexcheck on raw genotype file which
# contains non-autosome chromosomes.

plink --bfile $bfile --check-sex --out $bfile

#Produce a list of individuals with discordant sex data:

grep PROBLEM ${bfile}.sexcheck > gender_mis-identification_check.FAILED_QC

#The file will contain the family IDs (column 1) and individual ID (column 2) for these individuals. #Column 3 denotes ascertained sex and #column 4 denotes
# sex according to genotype data (1=male, 2=female). 
# When the homozygosity rate is more than 0.2 but less than 0.8, the genotype data are inconclusive regarding the sex of an individual and these are 
# marked in column 4 with a 0.

#Report the IDs of individuals with discordant sex information to those who conducted sex phenotyping. If discrepancy cannot be resolved, 
# add the family ID (FID) and individual ID (IID) of the samples to a QC file and exclude from further analysis. 

#b.	Individuals with elevated missing data rates or outlying heterozygosity rate; 

#Create the plink files xxxx.imiss and xxxx.lmiss for sample based and variant based missing SNPs, respectively. xxxx.lmiss QC is used in the marker QC.
# Here, the fourth column in the .imiss file (N_MISS) denotes the number of missing SNPs 
#and the sixth column (F_MISS) denotes the proportion of missing SNPs per individual:

plink --bfile ${bfile}_clean_SNPs_autosome --missing --out ${bfile}_clean_SNPs_autosome

#Create the plink file xxxx.het, in which the third column denotes the observed number of homozygous genotypes [O(Hom)] and the fifth column denotes 
#the number of nonmissing genotypes [N(NM)] per individual:

plink --bfile ${bfile}_clean_SNPs_autosome --het --out ${bfile}_clean_SNPs_autosome


#Calculate the observed heterozygosity rate per individual using the formula:
#(N(NM) + O(Hom)) / N(NM)

#Create a graph in which the observed heterozygosity rate per individual is plotted on the x axis and the proportion of missing SNPs per individuals is 
#plotted on the y axis:

#See script /ifs/projects/proj043/analysis.dir/genotypes.dir/imiss-vs-het_modified.R
#Modified from /ifs/projects/proj043/analysis.dir/genotypes.dir/Anderson_et_al_2010_Nat_Protocols.dir/imiss-vs-het.R

#At the cmd line run: 

Rscript ${base_directory_scripts}imiss-vs-het_modified.R ${bfile}_clean_SNPs_autosome

#Examine the plot to decide QC thresholds at which to exclude individuals based on elevated missing genotypes or extreme heterozygosity. 
#Ref. above excluded individuals with a genotype failure rate >= 0.03 (vertical dashed line) and/or a heterozygosity rate Â± 3 s.d. from the mean
#(horizontal dashed lines).

#Add FID and IID of samples which fail QC:
#The script imiss-vs-het.R generates a table missing_genotypes_and_het_rate.FAILED_QC with the IDs of individuals who failed this QC.

#c1.	Identification of related or duplicated individuals

#Reduce the number of SNPs used to create the identity by descent (IBS) matrix by pruning the data set so that no pair of SNPs (within a given number of 
#base pairs) has an r2 value greater than a given threshold (typically 0.2). This reduces computational complexity.
#Check http://pngu.mgh.harvard.edu/~purcell/plink/summary.shtml#prune
#First create the list of SNPs that are in LD with each other from the raw data file:

plink --bfile ${bfile}_clean_SNPs_autosome --indep-pairwise 50 5 0.2

#The command specifies 50 5 0.2 which would a) consider a window of 50 SNPs, b) calculate LD between each pair of SNPs in the window, 
#c) remove one of a pair of SNPs if the LD is greater than 0.2, d) shift the window 5 SNPs forward and repeat the procedure. 
#--indep-pairwise parameters are window size, step and r^2 threshold. Another way of filtering is with sliding windows instead of pairwise (--indep).

#Two files are generated, plink.prune.in and plink.prune.out. 
#Generate pairwise IBS for all pairs of individuals based on the reduced marker set:

plink --bfile ${bfile}_clean_SNPs_autosome --extract plink.prune.in --genome \
	--out ${bfile}_clean_SNPs_autosome_pruned

#With plink 1.07 I previously ran this with qsub, files are in /ifs/projects/proj043/analysis.dir/genotypes.dir/qsub_params_for_plink_IBS.sh 
#and
#qsub_plink_IBS.sh

#qsub qsub_params_for_plink_IBS.sh

#This generates a .genome file amongst others. 

#Change file names so IBD R script can run (.imiss and .genome must have same prefix):

ln -s ${bfile}_clean_SNPs_autosome_pruned.genome ${bfile}_clean_SNPs_autosome.genome

#To identify all pairs of individuals with an IBD > 0.1875, run R script below (could also use perl run-IBD-QC.pl but R results more complete 
#plus generates a plot):

Rscript ${base_directory_scripts}plot-IBD_modified.R ${bfile}_clean_SNPs_autosome

#IBD cut-offs Anderson 2010 explanation: 
#IBD>0.98 for duplicates or monozygotic twins, IBD=0.5 for first-degree relatives, IBD=0.25 for second-degree relatives and
#IBD=0.125 for third-degree relatives. Owing to genotyping error, LD and population structure, there is often some variation.
#It is typical to remove one individual from each pair with an IBD value of >0.1875, halfway between third- and second-degree relatives. 


#Perl script is from Anderson 2010 Nat Protocols, in /ifs/projects/proj043/analysis.dir/genotypes.dir/Anderson_et_al_2010_Nat_Protocols.dir/run-IBD-QC.pl
#This looks at the individual call rates stored in xxx.imiss and outputs the IDs of the individual with the lowest call rate to 'fail-IBD-QC xxx' 
#for subsequent removal.


#c2.	Identification of individuals of divergent ancestry

#Merge study genotypes to HapMap Phase III (HapMap3) data from four ethnic populations. 
#I'm currently using SNPs from Anderson et al. 2010. 
#TO DO: Finer population sub-structure requires more populations (e.g. within Europe).
# (a) Create a new BED file, excluding SNPs from the study data that do not feature in the genotype data of the four original HapMap3 populations:

#ln -s /ifs/projects/proj043/analysis.dir/genotypes.dir/Anderson_et_al_2010_Nat_Protocols.dir/hapmap3r2_CEU.CHB.JPT.YRI.* .

plink --bfile ${bfile}_clean_SNPs_autosome --extract hapmap3r2_CEU.CHB.JPT.YRI.no-at-cg-snps.txt --make-bed \
	--out ${bfile}_clean_SNPs_autosome.Anderson_hapmap_snps


# (b) Merge the raw-GWA-data.hapmap-snps files with the HapMap data and extract the pruned SNP set:
# This errors due to +/- strand problem, use --flip as below.

plink --bfile ${bfile}_clean_SNPs_autosome.Anderson_hapmap_snps \
	--bmerge hapmap3r2_CEU.CHB.JPT.YRI.founders.no-at-cg-snps \
	--extract plink.prune.in --make-bed --out ${bfile}_clean_SNPs_autosome.Anderson_hapmap_snps_hapmap3r2.pruned

#If this errors with (in plink 1.07) Â´ERROR: Stopping due to mis-matching SNPs -- check +/- strand?Â´, it is likely due to problem
# with strand flipping. 
#The alleles at each marker must be aligned to the same DNA strand to allow the study data to merge correctly. 
#Because not all SNPs are required for this analysis, A->T and C->G SNPs, which are more difficult to align, can be omitted. 
#Problem SNPs are saved by plink to the .missnp file. 
#Re-run command above (a) with --flip .pruned-merge.missnp:

plink --bfile ${bfile}_clean_SNPs_autosome --extract hapmap3r2_CEU.CHB.JPT.YRI.no-at-cg-snps.txt \
	--flip ${bfile}_clean_SNPs_autosome.Anderson_hapmap_snps_hapmap3r2.pruned-merge.missnp \
	--make-bed \
	--out ${bfile}_clean_SNPs_autosome.Anderson_hapmap_snps

#Then re-run (b) (the --bmerge command) exactly as above:
plink --bfile ${bfile}_clean_SNPs_autosome.Anderson_hapmap_snps --bmerge hapmap3r2_CEU.CHB.JPT.YRI.founders.no-at-cg-snps \
	--extract plink.prune.in --make-bed --out ${bfile}_clean_SNPs_autosome.Anderson_hapmap_snps_hapmap3r2.pruned


#Create a copy of the output BIM and FAM files just generated:
cp ${bfile}_clean_SNPs_autosome.Anderson_hapmap_snps_hapmap3r2.pruned.bim \
	${bfile}_clean_SNPs_autosome.Anderson_hapmap_snps_hapmap3r2.pruned.pedsnp

cp ${bfile}_clean_SNPs_autosome.Anderson_hapmap_snps_hapmap3r2.pruned.fam \
	${bfile}_clean_SNPs_autosome.Anderson_hapmap_snps_hapmap3r2.pruned.pedind

#Conduct a PCA on the merged data (requires smartpca.pl from EIGENSOFT, see dependencies above). Files are from the previous output 
#plus 'pca-populations.txt' file that specifies populations columns:
# smartpca is part of ftp://pricelab:pricelab@ftp.broadinstitute.org/EIGENSOFT/EIG-6.1.2.tar.gz
 
#${base_directory_scripts}smartpca.pl -i ${bfile}_clean_SNPs_autosome.Anderson_hapmap_snps_hapmap3r2.pruned.bed \
#        -a ${bfile}_clean_SNPs_autosome.Anderson_hapmap_snps_hapmap3r2.pruned.pedsnp \
#        -b ${bfile}_clean_SNPs_autosome.Anderson_hapmap_snps_hapmap3r2.pruned.pedind \
#        -o ${bfile}_clean_SNPs_autosome.Anderson_hapmap_snps_hapmap3r2.pruned.pca \
#        -p ${bfile}_clean_SNPs_autosome.Anderson_hapmap_snps_hapmap3r2.pruned.plot \
#        -e ${bfile}_clean_SNPs_autosome.Anderson_hapmap_snps_hapmap3r2.pruned.eval \
#        -l ${bfile}_clean_SNPs_autosome.Anderson_hapmap_snps_hapmap3r2.pruned.log \
#        -k 2 -t 2 -w pca-populations.txt

# Updated to use flashpca instead (https://github.com/gabraham/flashpca):
# Running as suggested but repeating some steps:
# TO DO: clean up update to flashpca and remove steps used before for smartpca

# Prune data based on LD and exclude regions:
plink --bfile ${bfile}_clean_SNPs_autosome --indep-pairwise 1000 50 0.05 --exclude range exclusion_regions_hg19.txt --out flashpca

# Exract variants from the pruning and create new file (10,000 to 50,000 SNPs are needed):
plink --bfile ${bfile}_clean_SNPs_autosome --extract flashpca.prune.in --make-bed --out ${bfile}_clean_SNPs_autosome_pruned

# Run flashpca:
${base_directory_scripts}flashpca_x86-64 --mem low --bfile ${bfile}_clean_SNPs_autosome_pruned --numthreads 8 --suffix _${bfile}_clean_SNPs_autosome_pruned.txt

#Create a scatter diagram of the first two principal components, including all individuals in the file raw-GWA-data.hapmap3r2.pruned.pca.evec 
#(the first and second principal components are columns 2 and 3, respectively). Use the data in column 4 to color the points according to sample origin. 
#Use the modified Anderson et al. 2010 plot-pca-results_modified.R to plot and extract IDs from individuals failing this QC:
# This script is for smartpca:

Rscript ${base_directory_scripts}plot-pca-results_modified.R ${bfile}_clean_SNPs_autosome.Anderson_hapmap_snps_

#Check the thresholds to apply for exclusion of individuals based on ancestry. Currently at 0.072 for PC2 as suggested.

# Run for flashpca results:


#TO DO: Run fine-scale ancestry stratification analysis with closer references within Europe using CEU, TSI, GBR, FIN and IBS samples from 
#www.1000genomes.org. Robust identification of fine-scale population structure often requires the construction of many (2-10) 
#principal components (Anderson et al 2010 protocol suggestions).

#	Removal of all individuals failing the QC checks
#Concatenate all files listing individuals who fail the previous QC steps into a single file with unique IDs:

cat *FAILED_QC | sort -k1 | head -n -3 > FAILED-QC-INDIVIDUALS.txt

#Remove individuals who failed QC from the data set:

plink --bfile ${bfile}_clean_SNPs_autosome --remove FAILED-QC-INDIVIDUALS.txt --make-bed \
	--out ${bfile}_clean_SNPs_autosome_individuals

#Individuals and SNPs failing QC steps will be removed and reported at each step. 

# Generate a report of allele frequencies after removal of low quality individuals:

plink --bfile ${bfile}_clean_SNPs_autosome_individuals --freq --out ${bfile}_clean_SNPs_autosome_individuals
plink --bfile ${bfile}_clean_SNPs_autosome_individuals --freqx --out ${bfile}_clean_SNPs_autosome_individuals

# Get frequency report for SNPs of interest:

grep -wf $SNPs_of_interest ${bfile}_clean_SNPs_autosome_individuals.frq > \
        ${SNPs_of_interest}.frq

grep -wf $SNPs_of_interest ${bfile}_clean_SNPs_autosome_individuals.frqx > \
	${SNPs_of_interest}.frqx

#References: PLINK (Purcell, Neale et al., 2007), related software and protocols (Anderson, Pettersson et al., 2010; Winkler, Day et al., 
#2014; Sham and #Purcell, 2014).

#########################


@follows(xxx)
def sampleQC():
    '''sampleQCsanity target'''
    pass

'''
-----

#. VCF check sanity (strand, problematic SNPs, etc.)
TO DO look up tools and insert command into Ruffus, these already exist, plink2 has commands for this.

'''

@follows(xxx)
def VCFsanity():
    '''VCFsanity target'''
    pass

##################################################################
# ---------------------------------------------------
# Generic pipeline tasks
@follows(xxx)
def full():
    pass

##################################################################
# ---------------------------------------------------
# Generic pipeline tasks for CGATReport:

@follows(mkdir("report"))
def build_report():
    '''build report from scratch. Any existing report will be overwritten.'''

    E.info("starting report build process from scratch")
    P.run_report(clean=True)


@follows(mkdir("report"))
def update_report():
    '''update report.

    This will update a report with any changes inside the report
    document or code. Note that updates to the data will not cause
    relevant sections to be updated. Use the cgatreport-clean utility
    first.
    '''

    E.info("updating report")
    P.run_report(clean=False)


@follows(update_report)
def publish_report():
    '''publish report in the CGAT downloads directory.'''

    E.info("publishing report")
    P.publish_report()

##################################################################
# ---------------------------------------------------
# See Steve's way of reporting:
# https://github.com/snsansom/scseq/blob/master/pipelines/pipeline_scrnaseq.py

# --------------------- < generic pipeline tasks > -------------------------- #

'''
@follows(mkdir("notebook.dir"))
@transform(glob.glob(os.path.join(os.path.dirname(__file__),
                                  "pipeline_notebooks",
                                  os.path.basename(__file__)[:-len(".py")],
                                  "*")),
           regex(r".*/(.*)"),
           r"notebook.dir/\1")
def notebooks(infile, outfile):
    ' '''Utility function to copy the notebooks from the source directory
       to the working directory''' '

    shutil.copy(infile, outfile)


@follows(quantitation, qc, notebooks)
def full():
    pass

print sys.argv

if __name__ == "__main__":
	sys.exit(P.main(sys.argv))

# See:
# https://github.com/snsansom/scseq/tree/master/pipelines/pipeline_notebooks/pipeline_scrnaseq
'''

##################################################################
# ---------------------------------------------------
# The end:

print sys.argv

if __name__ == "__main__":
    sys.exit(P.main(sys.argv))
